# ğŸ§  Bridging Lab and Industry: Practical SPA-GPT on Cryptosystems Boosted by LSTM and Simulated Annealing

> ğŸš§ *Work in Progress!*  
> This repository contains the **experimental code** and **dataset** for our upcoming paper  
> *"Bridging Lab and Industry: Practical SPA-GPT on Cryptosystems Boosted by LSTM and Simulated Annealing"* ğŸ’¡  

---

## ğŸŒŸ Overview

ğŸ” **Simple Power Analysis (SPA)** is a fundamental approach in side-channel analysis of cryptosystems, but it often demands intensive manual effort for **trace segmentation**.  

âœ¨ The original **SPA-GPT** framework (CHES 2024) introduced reinforcement learning to automate segmentation, but its **low efficiency** and focus on **public-key algorithms** restricted its broader application.  

ğŸš€ In this project, we propose a **practical and efficient enhancement** to SPA-GPT â€” integrating **Long Short-Term Memory (LSTM)** networks and an **attention mechanism**, together with a **Simulated Annealing-based Deep Q-Network policy**.   
ğŸ’¡ Experiments show a **50.34%â€“94.24% boost in time efficiency** and an **80% reduction in model parameters** compared to the original SPA-GPT.

---

## ğŸ“‚ Repository Structure

We are currently organizing the code and uploading it gradually. It will be updated regularly, so please refer to the latest version. ğŸ‰
